{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b662348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import time\n",
    "import gc\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae12ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run align_tools_cython.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7beb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%run _NWTW.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76970a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DTWStar.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ba16dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SET = 'toy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b374faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_LIST = Path(f'cfg_files/queries.train.{TRAIN_SET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab4b7065",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEMS = ['dtw1', 'dtw2', 'dtw3', 'dtw4', 'subseqdtw1', 'subseqdtw2', 'subseqdtw3', 'nwtw', 'dtwstarv02']\n",
    "BENCHMARKS = ['matching', 'subseq20', 'subseq30', 'subseq40', 'partialStart', 'partialEnd', 'partialOverlap', \n",
    "              'pre_5', 'pre_10', 'pre_20', 'post_5', 'post_10', 'post_20', 'preA_postB_5', 'preA_postB_10', \n",
    "              'preA_postB_20']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "567420c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_root = Path('../ttmp/Chopin_Mazurkas_features')\n",
    "FEAT_DIRS = {}\n",
    "\n",
    "for benchmark in BENCHMARKS:\n",
    "    if benchmark == 'partialOverlap':\n",
    "        FEAT_DIRS[benchmark] = ([features_root/'partialStart', features_root/'partialEnd'])\n",
    "    elif 'preA_postB' in benchmark:\n",
    "        sec = benchmark.split('_')[-1]\n",
    "        FEAT_DIRS[benchmark] = ([features_root/f'pre_{sec}', features_root/f'post_{sec}'])\n",
    "    else:\n",
    "        FEAT_DIRS[benchmark] = [features_root/f'{benchmark}', features_root/'original']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c556bb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = {'dtw1': np.array([1,1,1,2,2,1]).reshape((-1,2)),\n",
    "        'dtw2': np.array([1,1,1,2,2,1]).reshape((-1,2)),\n",
    "        'dtw3': np.array([1,1,1,0,0,1]).reshape((-1,2)),\n",
    "        'dtw4': np.array([1,1,1,0,0,1]).reshape((-1,2)),\n",
    "        'subseqdtw1': np.array([1,1,1,2,2,1]).reshape((-1,2)),\n",
    "        'subseqdtw2': np.array([1,1,1,2,2,1]).reshape((-1,2)),\n",
    "        'subseqdtw3': np.array([1,1,1,2,2,1]).reshape((-1,2)),\n",
    "        'nwtw': 0, # transitions are specified in NWTW algorithm\n",
    "        'dtwstarv02': np.array([1,1,1,2,2,1]).reshape((-1,2))\n",
    "        }\n",
    "weights = {'dtw1': np.array([2,3,3]),\n",
    "          'dtw2': np.array([1,1,1]),\n",
    "          'dtw3': np.array([2,1,1]),\n",
    "          'dtw4': np.array([1,1,1]),\n",
    "          'subseqdtw1': np.array([1,1,2]),\n",
    "          'subseqdtw2': np.array([2,3,3]),\n",
    "          'subseqdtw3': np.array([1,1,1]),\n",
    "          'nwtw': 0, # weights are specified in NWTW algorithm\n",
    "          'dtwstarv02': np.array([2,3,3])\n",
    "          }\n",
    "other_params = {'dtwstarv02': {'buffer': 10/(512/22050)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01626c9f",
   "metadata": {},
   "source": [
    "# Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b2ab6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outfile(outdir, benchmark, system, queryid):\n",
    "    outpath = (outdir / benchmark / system)\n",
    "    outpath.mkdir(parents=True, exist_ok=True)\n",
    "    outfile = (outpath / queryid).with_suffix('.pkl')\n",
    "    return outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "400d74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_system(system, F1, F2, outfile):\n",
    "    \n",
    "    subseq = 'subseq' in system\n",
    "    \n",
    "    if system == 'dtwstarv02':\n",
    "        C = 1 - L2norm(F1).T @ L2norm(F2)\n",
    "        best_cost, wp, debug = dtwstar_v2a(C, steps=steps[system], weights=weights[system], buffer=other_params[system]['buffer'])\n",
    "    elif system == 'nwtw':\n",
    "        wp = alignNWTW(F1, F2, downsample=1, gamma=0.346, profile = False)\n",
    "    else:\n",
    "        if subseq and (F2.shape[1] < F1.shape[1]):\n",
    "            # Cython DTW implementation\n",
    "            wp = alignDTW(F2, F1, steps=steps[system], weights=weights[system], downsample=1, outfile=outfile, subseq=subseq)\n",
    "            wp = wp[::-1,:]\n",
    "        else:\n",
    "            # Cython DTW implementation\n",
    "            wp = alignDTW(F1, F2, steps=steps[system], weights=weights[system], downsample=1, outfile=outfile, subseq=subseq)\n",
    "            \n",
    "    if wp is not None:\n",
    "        pickle.dump(wp, open(outfile, 'wb'))\n",
    "    else:\n",
    "        # currently handling None outputs in alignment algorithms by writing None to output file\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1e1aade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all_benchmarks(outdir):\n",
    "    parts_batch = []\n",
    "    queryids = []\n",
    "    with open(QUERY_LIST, 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            parts = line.strip().split(' ')\n",
    "            assert len(parts) == 2\n",
    "            queryid = os.path.basename(parts[0]) + '__' + os.path.basename(parts[1])\n",
    "            \n",
    "            parts_batch.append(parts)\n",
    "            queryids.append(queryid)\n",
    "            \n",
    "    for benchmark in BENCHMARKS:\n",
    "#         run_benchmark(benchmark, FEAT_DIRS[benchmark][0], FEAT_DIRS[benchmark][1], parts_batch[0], outdir, queryids[0])\n",
    "        run_benchmark_batch(benchmark, FEAT_DIRS[benchmark][0], FEAT_DIRS[benchmark][1], parts_batch, outdir, queryids, n_cores=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7f33ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark_batch(benchmark, featdir1, featdir2, parts_batch, outdir, queryids, n_cores):\n",
    "    inputs = []\n",
    "    assert len(parts_batch) == len(queryids)\n",
    "    \n",
    "    for i in range(len(parts_batch)):\n",
    "        featfile1 = (featdir1 / parts_batch[i][0]).with_suffix('.npy')\n",
    "        featfile2 = (featdir2 / parts_batch[i][1]).with_suffix('.npy')\n",
    "        \n",
    "        F1 = np.load(featfile1)\n",
    "        F2 = np.load(featfile2)\n",
    "        \n",
    "        for system in SYSTEMS:\n",
    "            inputs.append((system, F1, F2, get_outfile(outdir, benchmark, system, queryids[i])))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = multiprocessing.cpu_count()-1)\n",
    "    pool.starmap(align_system, inputs)\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3627a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_benchmark(benchmark, featdir1, featdir2, parts, outdir, queryid):\n",
    "    featfile1 = (featdir1 / parts[0]).with_suffix('.npy')\n",
    "    featfile2 = (featdir2 / parts[1]).with_suffix('.npy')\n",
    "\n",
    "    F1 = np.load(featfile1)\n",
    "    F2 = np.load(featfile2)\n",
    "        \n",
    "    # run all baselines\n",
    "    for system in SYSTEMS:\n",
    "        align_system(system, F1, F2, get_outfile(outdir, benchmark, system, queryid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35d8ee2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 9493.67it/s]\n"
     ]
    }
   ],
   "source": [
    "outdir = Path(f'experiments_train/{TRAIN_SET}')\n",
    "run_all_benchmarks(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc64734d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c463a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc147d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
