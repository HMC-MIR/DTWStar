{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f3feae",
   "metadata": {},
   "source": [
    "# DTW* v0.2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0740e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1b50ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def dtwstar_v2a(C, steps, weights, buffer=1):\n",
    "    '''\n",
    "    Implementation of DTW Star version 0.2a.  \n",
    "    \n",
    "    Inputs\n",
    "    C: pairwise cost matrix\n",
    "    steps: a numpy matrix specifying the allowable transitions.  It should be of\n",
    "        dimension (L, 2), where each row specifies (row step, col step)\n",
    "    weights: a array that specifies the multiplicative weights for each transition\n",
    "        type.  The length of this array must match the number of possible transitions.\n",
    "    buffer: specifies \n",
    "    \n",
    "    Outputs\n",
    "    best_cost: the best average cost per manhattan block\n",
    "    path: the estimated warping path, specified as a 2xN array\n",
    "    debug: Debugging information for examining the average cost per manhattan block for each \n",
    "        of the candidate ending positions.\n",
    "    '''\n",
    "    \n",
    "    # initialize\n",
    "    D = np.zeros(C.shape)\n",
    "    B = np.zeros(C.shape, dtype=np.int8)\n",
    "    P = np.zeros(C.shape, dtype=np.int32)\n",
    "    D[0,:] = C[0,:]\n",
    "    D[:,0] = C[:,0]\n",
    "    \n",
    "    # DP\n",
    "    for row in range(1,C.shape[0]):\n",
    "        for col in range(1, C.shape[1]):\n",
    "            \n",
    "            mincost = np.inf\n",
    "            minidx = -1\n",
    "            bestrprev = -1\n",
    "            bestcprev = -1\n",
    "            \n",
    "            # find best transition\n",
    "            for stepidx, step in enumerate(steps):\n",
    "                \n",
    "                (rstep, cstep) = step\n",
    "                prevrow = row - rstep\n",
    "                prevcol = col - cstep\n",
    "                \n",
    "                if prevrow >= 0 and prevcol >= 0:\n",
    "                    \n",
    "                    pathcost = D[prevrow, prevcol] + C[row, col] * weights[stepidx]\n",
    "                    \n",
    "                    if pathcost < mincost:\n",
    "                        \n",
    "                        mincost = pathcost\n",
    "                        minidx = stepidx\n",
    "                        bestrprev = prevrow\n",
    "                        bestcprev = prevcol\n",
    "            \n",
    "            # update D, B, P\n",
    "            D[row, col] = mincost\n",
    "            B[row, col] = minidx\n",
    "            if bestrprev == 0:\n",
    "                P[row, col] = bestcprev\n",
    "            elif bestcprev == 0:\n",
    "                P[row, col] = -1*bestrprev\n",
    "            else:\n",
    "                P[row, col] = P[bestrprev, bestcprev]\n",
    "            \n",
    "    #  backtrack\n",
    "    best_cost, best_r, best_c, debug = find_best_endpoint(D, P, buffer)\n",
    "    path = backtrace_dtwstar(D, B, steps, best_r, best_c)\n",
    "    path.reverse()\n",
    "    path = np.array(path).T \n",
    "    \n",
    "    return best_cost, path, debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72fc47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def find_best_endpoint(D, P, buffer):\n",
    "    '''\n",
    "    Determines the best location to begin backtracking from by comparing the average path cost\n",
    "    per manhattan block.\n",
    "    \n",
    "    Inputs\n",
    "    D: the cumulative cost matrix\n",
    "    P: the matrix specifying the starting location of the alignment path\n",
    "    buffer: specifies the length of a buffer region (in frames) to avoid short degenerate alignment paths\n",
    "        near the corners of the pairwise cost matrix.  This can be thought of as the minimum length that\n",
    "        needs to match in order to be considered a valid alignment path.\n",
    "    \n",
    "    Outputs\n",
    "    best_cost: the best average path cost per manhattan block\n",
    "    best_r: the row index of the best endpoint\n",
    "    best_c: the column index of the best endpoint\n",
    "    debug: debugging information for examining the average cost per manhattan block for each \n",
    "        of the candidate ending positions\n",
    "    '''\n",
    "    \n",
    "    # consider last row and column as candidates\n",
    "    candidates = [(D.shape[0]-1,i) for i in range(buffer, D.shape[1])] + [(i, D.shape[1]-1) for i in range(buffer, D.shape[0]-1)][::-1]\n",
    "    \n",
    "    best_cost = np.inf\n",
    "    best_r, best_c = -1, -1\n",
    "    debug = []\n",
    "    \n",
    "    for i, (r,c) in enumerate(candidates):\n",
    "                \n",
    "        # get alignment start location\n",
    "        if P[r,c] >= 0:\n",
    "            rstart, cstart = 0, P[r,c]\n",
    "        else:\n",
    "            rstart, cstart = -P[r,c], 0\n",
    "            \n",
    "        # calculate average cost per manhattan block\n",
    "        mdist = (r - rstart) + (c - cstart) # manhattan distance\n",
    "        avg_cost_per_mb = D[r,c] / mdist\n",
    "        \n",
    "        # keep best\n",
    "        if avg_cost_per_mb < best_cost:\n",
    "            best_cost = avg_cost_per_mb\n",
    "            best_r, best_c = r, c\n",
    "            \n",
    "        # debugging info\n",
    "        if r == D.shape[0]-1:\n",
    "            debug.append((c-D.shape[1]+1, avg_cost_per_mb, r, c))\n",
    "        else:\n",
    "            debug.append((D.shape[0]-1-r, avg_cost_per_mb, r, c))\n",
    "    \n",
    "    return best_cost, best_r, best_c, debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b7a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def backtrace_dtwstar(D, B, steps, rstart, cstart):\n",
    "    '''\n",
    "    Backtraces through the cumulative cost matrix D starting from a specified location.\n",
    "    \n",
    "    Arguments:\n",
    "    D: cumulative cost matrix\n",
    "    B: backtrace matrix\n",
    "    steps: a numpy matrix specifying the allowable transitions.  It should be of\n",
    "            dimension (L, 2), where each row specifies (row step, col step)\n",
    "    rstart: the row index to start backtracking from\n",
    "    cstart: the column index to start backtracking from\n",
    "    \n",
    "    Outputs\n",
    "    path: a python list of (row, col) coordinates for the optimal path.\n",
    "    '''\n",
    "    pos = (rstart, cstart)\n",
    "    path = []\n",
    "    path.append(pos)\n",
    "    while(pos[0] != 0 and pos[1] != 0):\n",
    "        (row, col) = pos\n",
    "        stepidx = B[row, col]\n",
    "        (rstep, cstep) = steps[stepidx]\n",
    "        pos = (row-rstep, col-cstep)\n",
    "        path.append(pos)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e5e3c",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336f155",
   "metadata": {},
   "source": [
    "The code below can be used to run DTW* v0.2a on specific examples, and to visualize the alignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664673d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e247b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968379ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def L2norm(F):\n",
    "    L2norm = np.sqrt(np.sum(F*F, axis = 0)) + 1e-9\n",
    "    Fnorm = F / L2norm.reshape((1,-1))\n",
    "    return Fnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6b74d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimestamps(annotfile1, annotfile2):\n",
    "    df1 = pd.read_csv(annotfile1, header=None, sep='\\s+', skiprows=3) \n",
    "    df2 = pd.read_csv(annotfile2, header=None, sep='\\s+', skiprows=3)\n",
    "    \n",
    "    df_merged = pd.merge(df1, df2, on=[2], how='inner')\n",
    "\n",
    "    return np.array(df_merged['0_x']), np.array(df_merged['0_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapFrame(r, c, Dshape, frames=False):\n",
    "    if frames: #  frames, use exact\n",
    "        if r == Dshape[0]-1:\n",
    "            val = c-D.shape[1]+1\n",
    "        else:\n",
    "            val = D.shape[0]-1-r\n",
    "    else: # seconds, use approximate\n",
    "        distr = np.abs(r-Dshape[0])\n",
    "        distc = np.abs(c-Dshape[1])\n",
    "        if distr < distc:\n",
    "            val = c-Dshape[1]\n",
    "        else:\n",
    "            val = Dshape[0]-r\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2798c362",
   "metadata": {},
   "outputs": [],
   "source": [
    "pieceid1 = 'Chopin_Op017No4_Beliavsky-2004_pid9152-13'\n",
    "#pieceid1 = 'Chopin_Op017No4_Luisada-1990_pid9055-13'\n",
    "#pieceid1 = 'Chopin_Op017No4_Kilenyi-1937_pid9164-13'\n",
    "#pieceid1 = 'Chopin_Op017No4_Magaloff-1977_pid5667267b-10'\n",
    "#pieceid1 = 'Chopin_Op017No4_Wasowski-1980_pid9111-13'\n",
    "type1 = 'partialStart'\n",
    "pieceid2 = 'Chopin_Op017No4_Clidat-1994_pid9067-13'\n",
    "#pieceid2 = 'Chopin_Op017No4_Paderewski-1912_pid5667274-09'\n",
    "#pieceid2 = 'Chopin_Op017No4_Rubinstein-1939_pid9049-13'\n",
    "#pieceid2 = 'Chopin_Op017No4_Smith-1975_pid9054-13'\n",
    "#pieceid2 = 'Chopin_Op017No4_Perahia-1994_pid54293-09'\n",
    "type2 = 'partialEnd'\n",
    "steps = np.array([1, 1, 1, 2, 2, 1]).reshape((-1,2))\n",
    "weights = np.array([2,3,3])\n",
    "hop_sec = 512/22050.\n",
    "buffer = 10 # in sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824003cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "featfile1 = f'/home/tjtsai/ttmp/Chopin_Mazurkas_features/{type1}/Chopin_Op017No4/{pieceid1}.npy'\n",
    "featfile2 = f'/home/tjtsai/ttmp/Chopin_Mazurkas_features/{type2}/Chopin_Op017No4/{pieceid2}.npy'\n",
    "F1 = np.load(featfile1)\n",
    "F2 = np.load(featfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d3f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type1 == 'original':\n",
    "    annotfile1 = f'/home/tjtsai/ttmp/Chopin_Mazurkas_Modified/annotations_beat/Chopin_Op017No4/{pieceid1}.beat'\n",
    "else:\n",
    "    annotfile1 = f'/home/tjtsai/ttmp/Chopin_Mazurkas_Benchmarks/{type1}/annotations_beat/Chopin_Op017No4/{pieceid1}.beat'\n",
    "if type2 == 'original':\n",
    "    annotfile2 = f'/home/tjtsai/ttmp/Chopin_Mazurkas_Modified/annotations_beat/Chopin_Op017No4/{pieceid2}.beat'\n",
    "else:\n",
    "    annotfile2 = f'/home/tjtsai/ttmp/Chopin_Mazurkas_Benchmarks/{type2}/annotations_beat/Chopin_Op017No4/{pieceid2}.beat'\n",
    "gt1, gt2 = getTimestamps(annotfile1, annotfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b0b6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1 - L2norm(F1).T @ L2norm(F2)\n",
    "start = time.time()\n",
    "best_cost, wp, debug = dtwstar_v2a(C, steps, weights, buffer/hop_sec)\n",
    "print(\"% s seconds\" % (time.time() - start))\n",
    "X = np.array(debug)\n",
    "times = X[:,0]*hop_sec\n",
    "scores = X[:,1]\n",
    "plt.plot(times, scores,'.')\n",
    "plt.axvline(times.min()+10, color='r')\n",
    "plt.axvline(times.max()-10, color='r')\n",
    "plt.axvline(mapFrame(gt1[-1], gt2[-1], (F1.shape[1]*hop_sec, F2.shape[1]*hop_sec)), color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f573b3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(wp[0,:]*hop_sec, wp[1,:]*hop_sec, 'y.')\n",
    "plt.plot(gt1, gt2, 'g')\n",
    "plt.legend(['pred', 'gt'])\n",
    "plt.xlim([0, F1.shape[1]*hop_sec+2])\n",
    "plt.ylim([0, F2.shape[1]*hop_sec+2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0f6504",
   "metadata": {},
   "source": [
    "# DTW* v0.2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5a96c",
   "metadata": {},
   "source": [
    "Seems to have about same accuracy as v0.2a, but is significantly slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e949c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @jit(nopython=True)\n",
    "# def dtwstar_v2b(C, steps, weights):\n",
    "    \n",
    "#     # initialize\n",
    "#     D = np.zeros(C.shape)\n",
    "#     B = np.zeros(C.shape, dtype=np.int8)\n",
    "#     P = np.zeros(C.shape, dtype=np.int32)\n",
    "#     D[0,:] = C[0,:]\n",
    "#     D[:,0] = C[:,0]\n",
    "    \n",
    "#     # DP\n",
    "#     for row in range(1,C.shape[0]):\n",
    "#         for col in range(1, C.shape[1]):\n",
    "#             mincost = np.inf\n",
    "#             minidx = -1\n",
    "#             bestrprev = -1\n",
    "#             bestcprev = -1\n",
    "#             for stepidx, step in enumerate(steps):\n",
    "#                 (rstep, cstep) = step\n",
    "#                 prevrow = row - rstep\n",
    "#                 prevcol = col - cstep\n",
    "#                 if prevrow >= 0 and prevcol >= 0:\n",
    "                    \n",
    "#                     # calculate avg cost per manhattan block\n",
    "#                     pathcost = D[prevrow, prevcol] + C[row, col] * weights[stepidx]\n",
    "#                     if P[prevrow, prevcol] >= 0:\n",
    "#                         mdist = row + (col - P[prevrow, prevcol])\n",
    "#                     else:\n",
    "#                         mdist = (row + P[prevrow, prevcol]) + col\n",
    "#                     cost_per_mb = pathcost / mdist\n",
    "                    \n",
    "#                     # select best transition based on avg cost per manhattan block\n",
    "#                     if cost_per_mb < mincost:\n",
    "#                         mincost = cost_per_mb\n",
    "#                         minidx = stepidx\n",
    "#                         bestrprev = prevrow\n",
    "#                         bestcprev = prevcol\n",
    "                        \n",
    "#             D[row, col] = D[bestrprev, bestcprev] + C[row, col] * weights[minidx]\n",
    "#             B[row, col] = minidx\n",
    "#             if bestrprev == 0:\n",
    "#                 P[row, col] = bestcprev\n",
    "#             elif bestcprev == 0:\n",
    "#                 P[row, col] = -1*bestrprev\n",
    "#             else:\n",
    "#                 P[row, col] = P[bestrprev, bestcprev]\n",
    "            \n",
    "#     #  backtrack\n",
    "#     best_cost, best_r, best_c, debug = find_best_endpoint(D, P)\n",
    "#     path = backtrace_dtwstar(D, B, steps, best_r, best_c)\n",
    "#     path.reverse()\n",
    "#     path = np.array(path)\n",
    "    \n",
    "#     return best_cost, path.T, debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fcc6d1",
   "metadata": {},
   "source": [
    "## SubseqDTW and NWTW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec08e3cb",
   "metadata": {},
   "source": [
    "Can be used to compare to SubseqDTW and NWTW alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bebac82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run _NWTW.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aab176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run align_tools_cython.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd79286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = []\n",
    "# times.append(time.time())\n",
    "# #best_cost, wp, debug = dtwstar_v2a(C, steps, weights, buffer/hop_sec)\n",
    "# wp1 = alignDTW(L2norm(F1), L2norm(F2), steps=steps, weights=weights, downsample=1, outfile=None, subseq=True)\n",
    "# times.append(time.time())\n",
    "# print(\"SubseqDTW: % s seconds\" % (times[1]-times[0]))\n",
    "# wp2 = alignNWTW(L2norm(F1), L2norm(F2), downsample=1, gamma=0.346, profile = False)\n",
    "# times.append(time.time())\n",
    "# print(\"NWTW: %s seconds\" % (times[2] - times[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83440f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(wp1[0,:]*hop_sec, wp1[1,:]*hop_sec, 'r')\n",
    "# plt.plot(wp2[0,:]*hop_sec, wp2[1,:]*hop_sec, 'b')\n",
    "# plt.plot(gt1, gt2, 'g')\n",
    "# plt.legend(['dtw','nwtw','gt'])\n",
    "# plt.xlim([0, F1.shape[1]*hop_sec+2])\n",
    "# plt.ylim([0, F2.shape[1]*hop_sec+2])\n",
    "# #plt.xlim([0,50])\n",
    "# #plt.ylim([0,80])\n",
    "# #plt.xlim([130,170])\n",
    "# #plt.ylim([150,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a24fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
