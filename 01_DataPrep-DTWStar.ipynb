{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to prep the data for the alignment task.  This includes computing audio features and generating a query list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import librosa as lb\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('../../data/')\n",
    "AUDIO_ROOT = DATA_ROOT / Path('Chopin_Mazurkas/wav_22050_mono')\n",
    "ANNOTATIONS_ROOT = DATA_ROOT / Path('Chopin_Mazurkas/annotations_beat')\n",
    "FEATURES_ROOT = Path('features') # directory which will store chroma features\n",
    "TRAIN_DATASET = \"toy\"\n",
    "\n",
    "%store DATA_ROOT\n",
    "%store FEATURES_ROOT\n",
    "%store TRAIN_DATASET\n",
    "\n",
    "train_files = Path('cfg_files/filelist.' + TRAIN_DATASET + '.txt')\n",
    "test_files = Path('cfg_files/filelist.test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(FEATURES_ROOT):\n",
    "    os.mkdir(FEATURES_ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features on clean audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we compute features on the audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chroma_single(infile, outfile, sr = 22050, hop_length=512):\n",
    "    y, sr = lb.core.load(infile, sr = sr)\n",
    "    #F = lb.feature.chroma_cens(y, sr=sr, hop_length=hop_length)\n",
    "    F = lb.feature.chroma_cqt(y, sr=sr, hop_length=hop_length, norm=2)\n",
    "    np.save(outfile, F)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chroma_batch(filelist, outdir, n_cores):\n",
    "\n",
    "    # prep inputs for parallelization\n",
    "    inputs = []\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            relpath = line.strip()\n",
    "            reldir, fileid = os.path.split(relpath)\n",
    "            featdir = outdir / reldir\n",
    "            featdir.mkdir(parents=True, exist_ok=True)\n",
    "            featfile = (featdir / fileid).with_suffix('.npy')\n",
    "            audiofile = (AUDIO_ROOT / relpath).with_suffix('.wav')\n",
    "            if os.path.exists(featfile):\n",
    "                print(f\"Skipping {featfile}\")\n",
    "            else:\n",
    "                inputs.append((audiofile, featfile))\n",
    "\n",
    "    # process files in parallel\n",
    "    pool = multiprocessing.Pool(processes = n_cores)\n",
    "    pool.starmap(compute_chroma_single, inputs)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by setting up DTW for audio without modification\n",
    "FEATS_CLEAN_DIR = FEATURES_ROOT / 'no_modification'\n",
    "compute_chroma_batch(train_files, FEATS_CLEAN_DIR, 24)\n",
    "compute_chroma_batch(test_files, FEATS_CLEAN_DIR, 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up modified data directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up directory structure below.\n",
    "```\n",
    "pre5\n",
    "├annotations_beat\n",
    "└wav_22050_mono\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will eventually include the following new_data_folder names:\n",
    "# subseq10, subseq30, partial_overlap,\n",
    "# pre5, pre10, pre15, pre20,\n",
    "# post5, post10, post15, post20,\n",
    "# pre_post5, pre_post10, pre_post15, pre_post20\n",
    "\n",
    "new_data_folder = DATA_ROOT / 'pre5'\n",
    "new_annotation_folder = new_data_folder / 'annotations_beat'\n",
    "new_audio_folder = new_data_folder / 'wav_22050_mono'\n",
    "\n",
    "new_data_folder.mkdir(exist_ok=True)\n",
    "new_annotation_folder.mkdir(exist_ok=True)\n",
    "new_audio_folder.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in `annotations_beat` directory. Annotation files do NOT have correct annotations for now. Instead, they are just copied over. The audio files directory `wav_22050_mono` will remain empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The /*/*.beat pattern ignores files outside of the mazurka directories \n",
    "# by specifying exactly one level of recursion. To remove this restriction,\n",
    "# use /**/*.beat.\n",
    "for old_annotations_file in glob.glob(str(ANNOTATIONS_ROOT) + '/*/*.beat', recursive=True):\n",
    "    mazurka, performance = os.path.split(\n",
    "                         os.path.relpath(old_annotations_file, ANNOTATIONS_ROOT))\n",
    "    mazurka = Path(mazurka)\n",
    "    performance = Path(performance)\n",
    "    \n",
    "    mazurka_dir = new_annotation_folder / mazurka\n",
    "    performance_file = mazurka_dir / performance\n",
    "    \n",
    "    if os.path.exists(mazurka_dir):\n",
    "        print(f\"Skipping creating {mazurka_dir} directory\")\n",
    "    else:\n",
    "        mazurka_dir.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "    if os.path.exists(performance_file):\n",
    "        print(f\"Skipping creating {performance_file}\")\n",
    "    else:\n",
    "        with open(old_annotations_file, 'r') as f:\n",
    "            preamble = [f.readline(), \n",
    "                        f.readline(),\n",
    "                        f.readline()]\n",
    "            \n",
    "            with open(performance_file, 'w') as new_annotations_file:\n",
    "                new_annotations_file.writelines(preamble)\n",
    "                \n",
    "                old_annotations = pd.read_csv(f, header=None, sep='\\s+')\n",
    "                new_annotations = old_annotations\n",
    "                \n",
    "                # Note this changes the times many decimal places beyond the annotation precision                \n",
    "                new_annotations.to_csv(new_annotations_file, header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just playing around with pandas for the other modifications\n",
    "\n",
    "# Select all beats greater than 7 seconds (if we've deleted the first 7 seconds)\n",
    "new_annotations = old_annotations[old_annotations[0] > 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute features on additional datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_dir(data_root, beg_silence, end_silence):\n",
    "    # Should dynamically construct audio file and compute chroma features\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate query list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate a file containing each pair of files to be aligned.\n",
    "\n",
    "The lines of this outfile have the form\n",
    "```\n",
    "piece_name/recording_name_1 piece_name/recording_name_2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query_list(filelist, outfile):\n",
    "    \n",
    "    # group files by piece\n",
    "    d = {}\n",
    "    with open(filelist, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split('/')\n",
    "            assert len(parts) == 2\n",
    "            piece, fileid = parts\n",
    "            if piece not in d:\n",
    "                d[piece] = []\n",
    "            d[piece].append(fileid)\n",
    "            \n",
    "    # print out all pairings\n",
    "    with open(outfile, 'w') as fout:\n",
    "        for piece in d:\n",
    "            num_recordings = len(d[piece])\n",
    "            for i in range(num_recordings):\n",
    "                fileid1 = d[piece][i]\n",
    "                for j in range(i+1, num_recordings):\n",
    "                    fileid2 = d[piece][j]\n",
    "                    line = f'{piece}/{fileid1} {piece}/{fileid2}\\n'\n",
    "                    fout.write(line)\n",
    "                    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_queries = 'cfg_files/query.' + TRAIN_DATASET + '.list'\n",
    "test_queries = 'cfg_files/query.test.list'\n",
    "generate_query_list(train_files, train_queries)\n",
    "generate_query_list(test_files, test_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
